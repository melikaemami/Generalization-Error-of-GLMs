
# Generalization Error of GLMs with ML-VAMP

This repository provides routines for predicting
the generaliation error of generalized linear models (GLMs)
in high-dimensional limits.  The code produces the plots 
in the paper:

> "Generalization Error of Generalized Linear Models in High Dimensions", https://arxiv.org/abs/2005.00180

Generalization error is a measure of how well a learned model
performs on previously unseen data, a basic goal in machine learning.
The paper provides an analytic procedure, called the 
state evolution (SE), for estimating the 
generalization error of certain classes of GLMs.
This code validates the formulae with numerical experiments in 
synthetic data.  A typical result is shown in the Figure below,
which is Fig. 4 in the paper.

![nonlinear simulation](https://github.com/melikaemami/Generalization-Error-of-GLMs/blob/master/nonlinear_sim_v1.png){ width=50% }

*Figure.  Median MSE on simulation of a nonlinear model along with the theoretical
 value from the SE predictions*

## Problem Formulation

We consider a GLM of the form,
```python
   p = X.dot(w), 
   y = out(p,d)
```
where `X` is a data matrix, `w` are unknown weights, `y` is a vector
of responses and `out(p,d)` is an output function with noise `d`.
The model is trained on data `(Xtr,ytr)` to obtain parameter
estimates `what`.  We then generate new test data 
data `(Xts,yts)`.  The generalization error is the average of
some score function,
```python
    yerr = score(yts, yts_hat),
```
where `yts` are the true output values on the test data,
and `yts_hat` are the predicted values using the parameter estimates
`what`.  

The paper provides a theoretical formula for the expected
generalzation in a certain high-dimensional limit.
This code performs simulations to validate the formula.
Specifically, three models are considered:

The code supports three possible models:

* `linear`:  Linear model with Gaussian noise output
* `logistic`:  Logistic binary classification
* `nonlinear`:  Non-linear output model.  This problem is non-convex.

## Running the Code 

The code has several parameters that can be adjusted for different 
numerical experiments.  In the paper, for each model above, 
three cases are considered

1. Data with i.i.d. features, training and test distributions are matched
2. Data with correlated features, training and test distributions are matched
3. Data with correlated features, training and test distributions are mismatched

For each case, the code fixes the number of features `p=1000` and
varies the sampling ratio `beta = n/p` from 0.2 to 3.  For each `beta`
value, `ntest` random problem instances are drawn, and the actual and predicted
generalization errors are measured for each test.  The code saves
the median values across the `ntest` results.
  
To run the three cases for the linear model run:
```bash
    python gen_test.py --test_type linear --dist_type const\
        --mod_pkg sklearn --save_dat --save_dir data_linear
    python gen_test.py --test_type linear --dist_type logn --corr 1\
        --mod_pkg sklearn --save_dat --save_dir data_linear
    python gen_test.py --test_type linear --dist_type logn --corr 0.5\
        --mod_pkg sklearn --save_dat --save_dir data_linear
```
This will create three files in the directory `data_linear`
corresponding to the three cases.  The results can then be plotted
with the command,
```bash
    python gen_plot.py --dist_type linear --save_dir data_linear  --out `linear_sim.png`
```
This will create a linear_sim.png file.

Similarly for the logistic model,
```bash
    python gen_test.py --test_type logistic --dist_type const\
        --mod_pkg sklearn --save_dat --save_dir data_logistic
    python gen_test.py --test_type logistic --dist_type logn --corr 1\
        --mod_pkg sklearn --save_dat --save_dir data_logistic
    python gen_test.py --test_type logistic --dist_type logn --corr 0.5\
        --mod_pkg sklearn --save_dat --save_dir data_logistic
```
For the non-linear model run,
```bash
    python gen_test.py --test_type nonlinear --dist_type const\
        --mod_pkg tf --save_dat --save_dir data_logistic
    python gen_test.py --test_type logistic --dist_type logn --corr 1\
        --mod_pkg tf --save_dat --save_dir data_logistic
    python gen_test.py --test_type logistic --dist_type logn --corr 0.5\
        --mod_pkg tf --save_dat --save_dir data_logistic
```
Note that the non-linear model uses the `--mod_pkg tf` option 
to fit using Tensorflow.

## Running Large Numbers of Trials
The above code only runs `ntest=10` trials per `beta` value.
The figures in the paper use 100 points.  You can simply set
`--ntest 100` in the above commands, but this will take some time
to complete.  The plots in the paper are generated by running
the above commands ten times on a cluster, each job with a different
batch number.  Sample *slurm* files are also included.

